env1:
    env_name: spoc  
    env_config:
        data_path: "/root/spoc_data/fifteen"
        prompt_format: grounding_worldmodeling
        use_state_reward: false
        chores_split: train
        task_type: FetchType
        success_threshold: 1.0
        max_actions_per_step: 3
        action_sep: ","
        resolution: 224
        fov: 90
        step_length: 0.2
        gpu_device: 0
    train_size: 1000  
    test_size: 32 

env2:
    env_name: spoc  
    env_config:
        data_path: "/root/spoc_data/fifteen"
        prompt_format: grounding_worldmodeling
        use_state_reward: false
        chores_split: train
        task_type: FetchType
        success_threshold: 1.0
        max_actions_per_step: 3
        action_sep: ","
        resolution: 224
        fov: 90
        step_length: 0.2
        gpu_device: 0
    train_size: 1000  
    test_size: 32 

env3:
    env_name: spoc  
    env_config:
        data_path: "/root/spoc_data/fifteen"
        prompt_format: grounding_worldmodeling
        use_state_reward: false
        chores_split: train
        task_type: FetchType
        success_threshold: 1.0
        max_actions_per_step: 3
        action_sep: ","
        resolution: 224
        fov: 90
        step_length: 0.2
        gpu_device: 0
    train_size: 1000  
    test_size: 32 

env4:
    env_name: spoc  
    env_config:
        data_path: "/root/spoc_data/fifteen"
        prompt_format: grounding_worldmodeling
        use_state_reward: false
        chores_split: train
        task_type: FetchType
        success_threshold: 1.0
        max_actions_per_step: 3
        action_sep: ","
        resolution: 224
        fov: 90
        step_length: 0.2
        gpu_device: 0
    train_size: 1000  
    test_size: 32 